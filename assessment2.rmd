## Assesment 2

In this assessment you will analyse tweets on a topic of your choice. You will explore the tweets as well as identify topics that people talk about in those tweets using topic modeling.

The general breakdown of the assessment is:

1. Tweets collecting (data mining) - should be done through a number of runs of the data mining script
2. Exploration and visualization of data (you can start doing this step as soon as you have your first data and then apply the same coding to a large dataset (=full dataset) to write up your insights
3. Topic modeling and visualization. Discuss your insights and identify distinct topics in your dataset

This project is done consistently over the course of the unit with installment submission to review the progres:

1. Submission in week 2: tasks 2.1 and 2.2 for the tweets collected during week 2.
2. Submission in week 3: tasks 2.1 and 2.2 for tweets collecting during week 3.
3. Submission in week 10: tasks 2.1, 2.2, 2.2 for tweets collected during week 2-10.

For each submission, include:
- .csv file with tweets
- .rmd document with completed tasks
-  .r script with your data mining for this submission
-  template per VUCollaborate

###  2.1 Tweets collecting (step 1):

Select the topic of your choice to research. The topic needs to be popular to have large number of tweets = many people talk about that topic on Twitter.

Run the script discussed in the class to collect tweets: you can use either topic as a keyword or hashtag (#keyword) for your query.

**Run your script every 3 days and save each dataset under a different filename (e.g. date_month.csv)**

Save your data from each run of the script as a separate file (see class notes)
You collect your tweets in weeks 2-4.

After you completed all data runs (end of week 4), you need to merge the files into one dataset (see class notes).

Remove duplicate entries from the dataset to have only unique entries (see class notes)

Upload your final dataset to a shared file storage (e.g. your free AWS S3 storage you used for Assignment 1), generate a shared link and use this link to load your dataset in `read_csv()` function, e.g.

### 2.2. Exploration and visualization of data

This step is based on a class workshop and uses `rtweet` package

1. Present the first 10 tweets from your dataset using `kable()`. Use `kable()` in all steps to present the tabular data
2. Visualise the frequency of your tweets
3. Identify top tweeting locations and present the first 10. Write 2-3 sentences on your insights from this.
4. Identify the most retweeted tweets and present top 20. Write 2-3 sentences on your insights from this
5. Identify the most liked tweets and present the first 15. Write 2-3 sentences on your insights from this
6. Identify top tweeters in your dataset and present the first 5. Write a sentence on your insights from this
7. Identify top emojis in your dataset and present the first 10.
8. Identify top hashtags in your dataset and present the first 10. Write 2-3 sentences on your insights from this
9. Identify top mentions in your dataset and present the first 10. Write 2-3 sentences on your insights from this
10. Get a list of all accounts that the top tweeter follows and present the first 5
11. Get a list of followers of the top tweeter and present the first 5

### 2.3. Topic modeling and visualization

This step is based on a class workshop and uses `topicmodels` package

1. Preprocess text from your dataset to tidy text and convert it to DocumentTermMatrix
2. Use `LDA()` function to create an LDA model. Experiment with different number of topics (`k=`).
Visualise the top 10 words from each topic to brainstorm on possible topics that they cover.

Write 2-3 sentences comparing LDA models you generated with different number of topics. Explain which model you think best covers your data. 

Come to a conclusion about the topics that your dataset presents.

### What to submit

- .rmd and .hmtl (knitted .rmd) file with your work addressing Steps 2-4
-  .r script with your data mining
-  .csv datasets your saved on each run and the final dataset (upload your dataset to VUCollaborate)
-  template with your details and link to your GitHub repo
